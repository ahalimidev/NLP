{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install emoji\n",
    "%pip install pandas\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('scrapped_data.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "def split_text_and_symbols(text):\n",
    "    if isinstance(text, str):\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        emoticon_set = set(char for char in text if char in emoji.EMOJI_DATA)\n",
    "        emoticon_list = [emoji.emojize(emoticon) for emoticon in emoticon_set]\n",
    "        sentence = ' '.join(words)\n",
    "\n",
    "        return sentence, emoticon_list\n",
    "    else:\n",
    "        return '', [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()\n",
    "\n",
    "dataset[['text', 'emoticon']] = data['content'].apply(split_text_and_symbols).apply(pd.Series)\n",
    "dataset['rating'] = data['score']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_lexicon_from_excel(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        lexicon = {row['emoticon'].strip().replace(\"'\", \"\"): int(row['polarity'])\n",
    "                   for _, row in df.iterrows()\n",
    "                   if isinstance(row['polarity'], int)}\n",
    "        return lexicon\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "def calculate_sentiment(symbols, lexicon):\n",
    "    sentiment_score = 0\n",
    "    unprocessable_emoticons = []\n",
    "    if symbols:\n",
    "        sentiment_score = sum(lexicon.get(char, 0) for char in symbols)\n",
    "        unprocessable_emoticons = [char for char in symbols if char not in lexicon]\n",
    "    return sentiment_score, unprocessable_emoticons\n",
    "\n",
    "nama_file_lexicon = 'dataset/emoticon.xlsx'\n",
    "\n",
    "lexicon = load_lexicon_from_excel(nama_file_lexicon)\n",
    "\n",
    "if lexicon is not None:\n",
    "    sentiment_data = dataset['emoticon'].apply(lambda x: calculate_sentiment(x, lexicon))\n",
    "    dataset['polarity_emotion'] = [sent[0] if sent[1] != [] else 0 for sent in sentiment_data]\n",
    "    dataset['unprocessable_emoticons'] = [sent[1] for sent in sentiment_data]\n",
    "\n",
    "    total_emoticons = len(dataset)\n",
    "    emoticons_processed = total_emoticons - sum(1 for emo_list in dataset['unprocessable_emoticons'] if emo_list)\n",
    "    success_percentage = (emoticons_processed / total_emoticons) * 100\n",
    "    failure_percentage = 100 - success_percentage\n",
    "\n",
    "    print(f\"Total emoticons: {total_emoticons}\")\n",
    "    print(f\"Emoticons processed: {emoticons_processed} ({success_percentage:.2f}%)\")\n",
    "    print(f\"Emoticons failed to process: {total_emoticons - emoticons_processed} ({failure_percentage:.2f}%)\")\n",
    "else:\n",
    "    print(\"Failed to load lexicon. Cannot continue computation.\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_emoticons = set()\n",
    "\n",
    "for value in dataset['unprocessable_emoticons']:\n",
    "    if isinstance(value, list) and value:\n",
    "        unique_emoticons.update(value)\n",
    "\n",
    "filtered_df = pd.DataFrame(list(unique_emoticons), columns=['emoticons'])\n",
    "\n",
    "#simpan data emoticon yang tidak bisa klasifikasi\n",
    "filtered_df.to_excel('gagal_proses/unique_emoticons.xlsx', index=False)\n",
    "\n",
    "#hapus kolom unprocessable_emoticons tidak butuh\n",
    "dataset.drop('unprocessable_emoticons', axis=1, inplace=True)\n",
    "#hasil akhir menjadi dataset\n",
    "dataset.to_excel('hasil/dataset.xlsx', index=False)\n",
    "\n",
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
